from transformers import AutoModelForCausalLM, AutoConfig
import os

model_dir = "./ATM_RAG_0603/adv_model"  # ä½ çš„ä¿å­˜è·¯å¾„

model = AutoModelForCausalLM.from_pretrained(model_dir)
config = AutoConfig.from_pretrained(model_dir)

vocab_from_weights = model.get_input_embeddings().weight.shape[0]
vocab_from_config = config.vocab_size

print(f"ğŸ” æƒé‡ä¸­çš„ vocab sizeï¼ˆembedding è¡Œæ•°ï¼‰: {vocab_from_weights}")
print(f"ğŸ“„ config.json ä¸­çš„ vocab size:         {vocab_from_config}")

if vocab_from_weights != vocab_from_config:
    print("âŒ vocab_size ä¸ä¸€è‡´ï¼Œä¼šå¯¼è‡´ vLLM æŠ¥é”™ï¼")
else:
    print("âœ… vocab_size ä¸€è‡´ï¼Œç†è®ºä¸Š vLLM å¯æ­£å¸¸åŠ è½½ã€‚")
